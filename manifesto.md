---
layout: default
title: Manifesto
permalink: /manifesto/
---

# Product IDEA Loop Manifesto

### A new way to build and ship software in the AI era.

Most teams do not run out of ideas.

They run out of affordable attempts.

For a long time, this made sense. Building software required scarce specialists, long planning cycles, and many handoffs. That old model still works in strong companies with strong teams.

But now AI has changed what is possible. One person can create working software much faster than before. The bottleneck is no longer just coding speed. It is how quickly a team can test assumptions and make better decisions.

The sprint was built to manage scarce builders.

The loop is built to maximize abundant attempts.

---

## How this manifesto relates to the index

- This manifesto defines principles and intent
- The [index](./index.md) defines the practical operating playbook (setups, workflows, and references)
- If wording drifts, preserve principle-level alignment first, then update operational guidance

---

## What IDEA means

**IDEA = Insight, Design, Engineering, Analysis.**

In plain terms:

- **Insight**: what problem are we solving and for whom?
- **Design**: what should the experience feel like?
- **Engineering**: how does it actually work?
- **Analysis**: how will we know it worked?

In IDEA, these happen together in the same session, not one after another through long handoffs.

IDEA loops can run in `single-player` mode (one owner) or `multi-player` mode (usually 2-3 collaborators).
Both modes are concurrent: insight, design, engineering, and analysis stay active in-session.

## Concurrent, not phased

Do not run IDEA as four sequential stages.

Not this:
Insight -> Design -> Engineering -> Analysis (separate handoffs across days)

Do this:
Keep all four active in the same working session. A new user insight can reshape the design in minutes. A design constraint can reduce engineering scope immediately. Early analysis instrumentation can change what you build next before the loop ends.

Think live studio, not relay race.

## What this is

- A practical working method for running `Insight + Design + Engineering + Analysis` concurrently
- A loop-based way to test assumptions, build artifacts, and decide quickly
- Usable in `single-player` mode or small `multi-player` teams (2-3)

## What this is not

- Not a governance model
- Not a replacement for functional expertise
- Not a mandatory org process or new reporting layer
- Not a license to skip safety, compliance, or quality review

## Strengths of this framework

- It lets non-technical founders start immediately in sandboxed environments
- It combats organizational atrophy and scarcity theater, replacing ticket-and-deck consensus with working evidence
- It exposes weak assumptions quickly, reducing costly rework and public embarrassment
- It counters sunk-cost fallacy by forcing explicit loop closure decisions
- It combines the speed of low-fidelity wireframing and vibe coding into a coherent AI-powered way of working

## A note on vibe coding

Vibe coding deserves real credit: it helped make app creation accessible to far more people.

That accessibility is a major unlock for IDEA loops.
Product IDEA Loop is different: it treats vibe coding as ignition, then raises quality through disciplined loops and explicit evidence.

But a working demo is the beginning, not the finish line.

Loopers should use vibe coding to accelerate starts, then raise quality through insight, design, engineering, and analysis working together.

## Flexing the Cross-Discipline Muscle

Anxiety around unfamiliar skills is normal in AI-native building.

Loop quality is highly sensitive to model choice, clarity of thought, prompting quality, taste, and critical thinking.

Loop speed and outcomes are extremely variable. Sometimes months of work collapse into a single prompt. Sometimes a simple task gets stuck for hours.

When progress stalls, move from panic to evidence: screenshots, decision notes, user feedback, metrics, and technical traces when needed.

The looper/pilot should train outside active work sessions: practice prompting, study what is happening behind the curtain, refine taste, and keep building cross-discipline muscle.

Be patient with the agent, and with yourself.

---

## What a loop is

A loop is one focused round of building and learning.

Most loops should run 1-6 hours.

Extend beyond 6 hours only while uncertainty is dropping and decision quality is improving.
If those signals stall, pause and close the loop.

You can pause at any time.

But every loop should close within 3 days (72 hours).

When a loop closes, capture three things:

1. Something concrete (a prototype, flow, screen, or working slice)
2. What you learned
3. What happens next (ship, iterate, pivot, or stop)

No zombie loops.

## How to judge loop success

A loop succeeds when it improves decision quality, even if it does not ship.

- It strengthens the idea or hypothesis
- It improves the starting point of the next loop
- It exposes weak assumptions early, while change is still cheap

Additional strong signals:

- The team reduced uncertainty per hour, not just produced more output
- A bad path was killed early with evidence (time saved is a win)
- The loop produced reusable assets (prompt, component, metric, playbook)
- Next-loop scope became sharper (clearer problem, tighter constraints, better questions)
- Risk moved from implicit to explicit (known unknowns became named decisions)

---

## Who can run loops

Anyone working on software ideas can run loops:

PMs, designers, engineers, founders, and cross-functional partners.

Yes, even non-coders can run early loops in sandbox environments with AI.

This does **not** remove expertise.

It removes the "permission bottleneck" at the start.

Experts still matter deeply for quality, scale, and safety.

---

## Why this helps

In traditional async handoffs, a wrong assumption can hide for weeks.

In a live loop, it can be exposed in hours.

A spec is a hypothesis, not a contract.

If an assumption breaks mid-loop, that is not failure.

That is the loop doing its job.

A loop is a win if it improves the starting conditions of the next loop.

---

## Guardrails

Fast does not mean reckless.

- Use sandbox first for exploration.
- Apply extra review for high-risk changes (security, privacy, money, legal/compliance, production infrastructure).
- Do not ship what you cannot explain.
- Do not measure value only by hours or ticket count.

In an AI-amplified system, effort is linear.

Leverage is not.

---

## The practical method

Start with one clear goal.

Build something real quickly.

Let insight, design, engineering, and analysis improve each other in real time.

Pause when needed.

Close intentionally.

Start the next loop stronger.

There is always another loop tomorrow.

For current tooling patterns, setup options, and references, see the framework index: [Product IDEA Loop](./index.md).

Instinct -> Insight -> Intelligence.

"I" evolves. I mature.
